name: Update data.json (daily)

on:
  # Manual run button in the Actions tab
  workflow_dispatch:
  # Nightly run (UTC). Adjust to your preference.
  schedule:
    - cron: '20 3 * * *'
  # Optional: re-generate when you change any scraper code or sources
  push:
    paths:
      - 'scraper/**'
      - '.github/workflows/update-data.yml'

permissions:
  contents: write  # needed to commit data.json back to the repo

concurrency:
  group: update-data
  cancel-in-progress: false

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          persist-credentials: true        # needed to push

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r scraper/requirements.txt

      # If you saved an OpenAI key in repo Settings → Secrets and variables → Actions
      # named OPENAI_API_KEY, the scraper will use it as an optional fallback.
      - name: Run scraper
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scraper/agent.py

      - name: Commit & push data.json
        run: |
          git config user.name  "actions-user"
          git config user.email "actions@github.com"
          git add data.json
          if ! git diff --cached --quiet; then
            git commit -m "chore: auto-update data.json ($(date -u +'%Y-%m-%dT%H:%M:%SZ'))"
            git push
          else
            echo "No changes to commit."
          fi
